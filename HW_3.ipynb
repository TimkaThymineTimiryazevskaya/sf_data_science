{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimkaThymineTimiryazevskaya/sf_data_science/blob/main/HW_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qRzcjd_s4-7"
      },
      "outputs": [],
      "source": [
        "#импорт библиотек\n",
        "import numpy as np #для матричных вычислений\n",
        "import pandas as pd #для анализа и предобработки данных\n",
        "import matplotlib.pyplot as plt #для визуализации\n",
        "import seaborn as sns #для визуализации\n",
        "\n",
        "from sklearn import linear_model #линейные моделиё\n",
        "from sklearn import tree #деревья решений\n",
        "from sklearn import ensemble #ансамбли\n",
        "from sklearn import metrics #метрики\n",
        "from sklearn import preprocessing #предобработка\n",
        "from sklearn.model_selection import train_test_split #сплитование выборки\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S39Mzxentd7c"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('_train_sem09__1_.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_kpYuSevmly"
      },
      "outputs": [],
      "source": [
        "X = data.drop(['Activity'], axis=1)\n",
        "y = data['Activity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQotuyMmwBMN"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9SaO3X_wyGo"
      },
      "source": [
        "**Логистическая регрессия**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5QgJpm9w5eM",
        "outputId": "ef794206-b8ab-4369-b166-6fa13a2febf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score на тестовом наборе: 0.79\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "log_reg = linear_model.LogisticRegression(max_iter = 50)\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_test_pred = log_reg.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZBi8MkDxg9b"
      },
      "source": [
        "**Вывод**: Без подбора гиперпараметров модель лог.регрессии дает f1-score 0.79"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utUpQB3Ex3v_",
        "outputId": "ba223f9f-b146-426c-9112-590573572afc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: 0.81\n"
          ]
        }
      ],
      "source": [
        "rf = ensemble.RandomForestClassifier(random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_test_pred = rf.predict(X_test)\n",
        "print('Test: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz_hZoHNyQmN"
      },
      "source": [
        "**Вывод**: Без подбора гиперпараметров модель случайного леса дает f1-score 0.81"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgk3C06oy17K"
      },
      "source": [
        "**Подбор гиперпараметров для лог.регрессии с помощью GridSeachCV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmzYtEefyZIj",
        "outputId": "7d55f8fd-5701-4d4a-896c-5e4a28eb911a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4.05 s, sys: 209 ms, total: 4.26 s\n",
            "Wall time: 41.7 s\n",
            "f1_score на тестовом наборе: 0.78\n",
            "Наилучшие значения гиперпараметров: {'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'penalty': ['l2', 'none'] ,\n",
        "              'solver': ['lbfgs', 'saga'], \n",
        "              }\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(\n",
        "        random_state=42, \n",
        "        max_iter=50 \n",
        "    ), \n",
        "    param_grid=param_grid, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search.fit(X_train, y_train) \n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для случайного леса с помощью GridSeachCV**"
      ],
      "metadata": {
        "id": "6uMpo64yhn2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdyOGTW3zrG3",
        "outputId": "bf262511-a15e-4ee0-cdc8-34d396253b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 26.7 s, sys: 2.56 s, total: 29.2 s\n",
            "Wall time: 39min 19s\n",
            "f1_score на тестовом наборе: 0.82\n",
            "Наилучшие значения гиперпараметров: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 5}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'min_samples_leaf': list(np.linspace(5, 30, 10, dtype=int)),\n",
        "              'max_depth': list(np.linspace(5, 15, 30, dtype=int)),\n",
        "              'criterion':['entropy','gini']\n",
        "              }\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(\n",
        "        random_state=42\n",
        "    ), \n",
        "    param_grid=param_grid, \n",
        "    cv=5, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search.fit(X_train, y_train) \n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод: Для случайного леса f1_score увеличился **"
      ],
      "metadata": {
        "id": "_3otjK7hitrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для лог.регрессии с помощью RandomizedSeachCV**"
      ],
      "metadata": {
        "id": "G2Zj7IEfh1wf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXBGIn9Q2LqK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2_k_gPNi2SN6",
        "outputId": "3242862d-eb13-4a84-8cc0-a4027ee54c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 22.9 s, sys: 1.94 s, total: 24.8 s\n",
            "Wall time: 37min 57s\n",
            "f1_score на тестовом наборе: 0.82\n",
            "Наилучшие значения гиперпараметров: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 5}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'penalty': ['l2', 'none'] ,\n",
        "              'solver': ['lbfgs', 'saga'], \n",
        "              }\n",
        "rand_search = RandomizedSearchCV(\n",
        "    estimator=linear_model.LogisticRegression(\n",
        "        random_state=42, \n",
        "        max_iter=50 \n",
        "    ), \n",
        "    param_distributions=param_grid, \n",
        "    cv=5, \n",
        "    n_iter = 10, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search.fit(X_train, y_train) \n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для случайного леса с помощью RandomizedSeachCV**"
      ],
      "metadata": {
        "id": "B_dzYOBlh96d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gTQYGw762fOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155094f0-1b1e-4d54-a01c-3599be828946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18.5 s, sys: 1.45 s, total: 20 s\n",
            "Wall time: 37min 2s\n",
            "f1_score на тестовом наборе: 0.82\n",
            "Наилучшие значения гиперпараметров: {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 5}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {'min_samples_leaf': list(np.linspace(5, 100, 50, dtype=int)),\n",
        "              'max_depth': list(np.linspace(1, 30, 50, dtype=int)),\n",
        "              'criterion':['entropy','gini']\n",
        "              }\n",
        "rand_search = RandomizedSearchCV(\n",
        "    estimator=ensemble.RandomForestClassifier(\n",
        "        random_state=42\n",
        "    ), \n",
        "    param_distributions=param_grid, \n",
        "    cv=5, \n",
        "    n_iter = 10, \n",
        "    n_jobs = -1\n",
        ")  \n",
        "%time grid_search.fit(X_train, y_train) \n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
        "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод: В обоих случаях f1 увеличился"
      ],
      "metadata": {
        "id": "hGgd7CdSi-NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для лог.регрессии с помощью Hyperopt**"
      ],
      "metadata": {
        "id": "d2a-L9FjiGJ6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L9vJ1Eoo2p32"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import hyperopt\n",
        "from hyperopt import hp, fmin, tpe, Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JTu913gM4cbe"
      },
      "outputs": [],
      "source": [
        "space_lin={'penalty': hp.choice('penalty',options=['l2', 'none'] ),'solver': hp.choice('solver',options=['lbfgs', 'saga']), \n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperopt_log(params, cv=5, X=X_train, y=y_train, random_state=42):\n",
        "    params = {'penalty': (params['penalty']), \n",
        "              'solver': (params['solver']), \n",
        "              }\n",
        "    model = linear_model.LogisticRegression (**params, random_state=42, max_iter=100)\n",
        "\n",
        "    model.fit(X, y)\n",
        "    score = metrics.f1_score(y, model.predict(X))\n",
        "    return -score"
      ],
      "metadata": {
        "id": "7uiXTYjlffJ0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "best=fmin(hyperopt_log, \n",
        "          space=space_lin, \n",
        "          algo=tpe.suggest,\n",
        "          max_evals=20, \n",
        "          trials=trials, \n",
        "          rstate=np.random.RandomState(42)\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tDZ8Hg0gGtI",
        "outputId": "c0312a95-82dc-4cbc-cd1b-078bdbe047e6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5%|▌         | 1/20 [00:09<02:56,  9.32s/it, best loss: -0.8720930232558138]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 2/20 [00:10<01:23,  4.62s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 3/20 [00:12<00:57,  3.37s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|██        | 4/20 [00:15<00:52,  3.25s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25%|██▌       | 5/20 [00:22<01:07,  4.52s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 6/20 [00:33<01:33,  6.64s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|███▌      | 7/20 [00:34<01:04,  4.92s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 8/20 [00:36<00:46,  3.86s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 9/20 [00:37<00:35,  3.19s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 10/20 [00:40<00:30,  3.05s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:48<00:41,  4.59s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|██████    | 12/20 [00:49<00:28,  3.61s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:59<00:38,  5.51s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 14/20 [01:01<00:25,  4.26s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|███████▌  | 15/20 [01:02<00:16,  3.38s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80%|████████  | 16/20 [01:03<00:11,  2.78s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|████████▌ | 17/20 [01:12<00:13,  4.50s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|█████████ | 18/20 [01:13<00:07,  3.56s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|█████████▌| 19/20 [01:23<00:05,  5.43s/it, best loss: -0.9102053325160895]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [01:25<00:00,  4.27s/it, best loss: -0.9102053325160895]\n",
            "Наилучшие значения гиперпараметров {'penalty': 1, 'solver': 0}\n",
            "CPU times: user 1min 22s, sys: 6.59 s, total: 1min 29s\n",
            "Wall time: 1min 25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = linear_model.LogisticRegression(\n",
        "    random_state=42, \n",
        "    penalty=(best['penalty']),\n",
        "    solver=(best['solver']),\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "JrAAQ-MQglVT",
        "outputId": "24d506d0-0e49-4f4f-9cb3-fe667ec51e34"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-310ccb11bba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'solver'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f1_score на тестовом наборе: {:.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \"\"\"\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"liblinear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"newton-cg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_solvers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;34m\"Logistic Regression supports only solvers in %s, got %s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mall_solvers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got 0."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для случайного леса с помощью Hyperopt**"
      ],
      "metadata": {
        "id": "hRVqfZp1iVac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Wbam3nOU2q96"
      },
      "outputs": [],
      "source": [
        "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
        "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
        "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "G4HAgDjD56h3"
      },
      "outputs": [],
      "source": [
        "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=42):\n",
        "    params = {'n_estimators': int(params['n_estimators']), \n",
        "              'max_depth': int(params['max_depth']), \n",
        "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
        "              }\n",
        "    model = ensemble.RandomForestClassifier(**params, random_state=42)\n",
        "\n",
        "    model.fit(X, y)\n",
        "    score = metrics.f1_score(y, model.predict(X))\n",
        "    return -score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9IeWHtig6NJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d17344-80dd-4fa1-db96-a57c9c8fdb87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [01:01<00:00,  3.09s/it, best loss: -0.9911233547597184]\n",
            "Наилучшие значения гиперпараметров {'max_depth': 24.0, 'min_samples_leaf': 2.0, 'n_estimators': 153.0}\n",
            "CPU times: user 58.7 s, sys: 683 ms, total: 59.4 s\n",
            "Wall time: 1min 1s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "best=fmin(hyperopt_rf, \n",
        "          space=space, \n",
        "          algo=tpe.suggest,\n",
        "          max_evals=20, \n",
        "          trials=trials, \n",
        "          rstate=np.random.RandomState(42)\n",
        "         )\n",
        "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0_9rke4k6UgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be0f08f-0538-4515-ea24-b77f41eb0962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score на тестовом наборе: 0.82\n"
          ]
        }
      ],
      "source": [
        "model = ensemble.RandomForestClassifier(\n",
        "    random_state=42, \n",
        "    n_estimators=int(best['n_estimators']),\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_samples_leaf=int(best['min_samples_leaf'])\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подбор гиперпараметров для случайного леса с помощью Optuna**"
      ],
      "metadata": {
        "id": "oOYWhX4Lic_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "PHNrc-qW6iRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cadcff4-3b8a-48d0-dd3e-774216efeb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from optuna) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.9.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna) (6.7.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (6.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.12.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9u3nWdD76rS-"
      },
      "outputs": [],
      "source": [
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "voPnDDxC6vu2"
      },
      "outputs": [],
      "source": [
        "def optuna_rf(trial):\n",
        "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
        "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
        "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
        "\n",
        "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                          max_depth=max_depth,\n",
        "                                          min_samples_leaf=min_samples_leaf,\n",
        "                                          random_state=42)\n",
        "  # обучаем модель\n",
        "  model.fit(X_train, y_train)\n",
        "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
        "\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kp8EC5a_65QE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae426d73-1ddd-4451-ddfd-c41dabe8e8c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-02-11 17:38:44,654]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:38:46,765]\u001b[0m Trial 0 finished with value: 0.9057527539779682 and parameters: {'n_estimators': 107, 'max_depth': 11, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.9057527539779682.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:38:50,362]\u001b[0m Trial 1 finished with value: 0.9278287461773701 and parameters: {'n_estimators': 171, 'max_depth': 20, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.9278287461773701.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:38:54,783]\u001b[0m Trial 2 finished with value: 0.9525835866261398 and parameters: {'n_estimators': 112, 'max_depth': 12, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.9525835866261398.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:38:59,871]\u001b[0m Trial 3 finished with value: 0.9087022900763359 and parameters: {'n_estimators': 143, 'max_depth': 13, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.9525835866261398.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:05,757]\u001b[0m Trial 4 finished with value: 0.9172013443324166 and parameters: {'n_estimators': 198, 'max_depth': 16, 'min_samples_leaf': 8}. Best is trial 2 with value: 0.9525835866261398.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:12,111]\u001b[0m Trial 5 finished with value: 0.989280245022971 and parameters: {'n_estimators': 140, 'max_depth': 18, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:14,975]\u001b[0m Trial 6 finished with value: 0.956548347613219 and parameters: {'n_estimators': 155, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:16,873]\u001b[0m Trial 7 finished with value: 0.9149130832570905 and parameters: {'n_estimators': 121, 'max_depth': 28, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:19,643]\u001b[0m Trial 8 finished with value: 0.9152127333945516 and parameters: {'n_estimators': 172, 'max_depth': 24, 'min_samples_leaf': 8}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:22,376]\u001b[0m Trial 9 finished with value: 0.9008567931456548 and parameters: {'n_estimators': 133, 'max_depth': 29, 'min_samples_leaf': 10}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:25,645]\u001b[0m Trial 10 finished with value: 0.9880404783808648 and parameters: {'n_estimators': 161, 'max_depth': 17, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:28,931]\u001b[0m Trial 11 finished with value: 0.9880331389996931 and parameters: {'n_estimators': 160, 'max_depth': 17, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:31,548]\u001b[0m Trial 12 finished with value: 0.9574793514836342 and parameters: {'n_estimators': 135, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.989280245022971.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:36,125]\u001b[0m Trial 13 finished with value: 0.9920343137254902 and parameters: {'n_estimators': 188, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:39,647]\u001b[0m Trial 14 finished with value: 0.9463414634146341 and parameters: {'n_estimators': 199, 'max_depth': 24, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:43,387]\u001b[0m Trial 15 finished with value: 0.9776416539050536 and parameters: {'n_estimators': 184, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:47,179]\u001b[0m Trial 16 finished with value: 0.9460201280878316 and parameters: {'n_estimators': 182, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:50,655]\u001b[0m Trial 17 finished with value: 0.9908144519289651 and parameters: {'n_estimators': 145, 'max_depth': 27, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:53,152]\u001b[0m Trial 18 finished with value: 0.9767441860465117 and parameters: {'n_estimators': 122, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n",
            "\u001b[32m[I 2023-02-11 17:39:56,018]\u001b[0m Trial 19 finished with value: 0.9580911593759559 and parameters: {'n_estimators': 149, 'max_depth': 26, 'min_samples_leaf': 4}. Best is trial 13 with value: 0.9920343137254902.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 2s, sys: 706 ms, total: 1min 3s\n",
            "Wall time: 1min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
        "study.optimize(optuna_rf, n_trials=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "yw6G6Aiz6_6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aead5bce-935a-4241-ce9a-57c37106885f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_score на тестовом наборе: 0.82\n"
          ]
        }
      ],
      "source": [
        "# рассчитаем точность для тестовой выборки\n",
        "model = ensemble.RandomForestClassifier(**study.best_params,random_state=42 )\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итог: При наилучших параметрах f1-score составил 0ю82 для тестововй выборки"
      ],
      "metadata": {
        "id": "ELhi72-FkGqI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JF-f1eTCihDA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPV0iRE/mzzkSFMJwxR9Av",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}